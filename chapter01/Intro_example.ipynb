{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probably the simplest BIP in the world\n",
    "\n",
    "## <font color=#CD853F> Contents of this notebook: </font>\n",
    "  * [Learning objectives](#r-learning-objectives)\n",
    "  * [The forward model](#r-the-forward-model)\n",
    "  * [The prior](#r-the-prior)\n",
    "  * [The noise distribution](#r-the-noise-distribution)\n",
    "  * [The data distribution](#r-the-data-distribution)\n",
    "  * [The likelihood function](#r-the-likelihood-function)\n",
    "  * [Maximum likelihood (ML) point estimate](#r-maximum-likelihood-ml-point-estimate)\n",
    "  * [The posterior distribution](#r-posterior)\n",
    "  * [Maximum a posteriori (MAP) estimate](#r-maximum-a-posteriori-map-estimate)\n",
    "  * [Sampling from the posterior](#r-sampling-from-the-posterior)\n",
    "\n",
    "## <font color=#CD853F> Learning objectives: </font> <a name=\"r-learning-objectives\"></a>\n",
    "  * Create a linear forward model object in CUQIpy and apply it to some parameters\n",
    "  * Create a distribution object in CUQIpy that represents the prior and the noise, and sample, and visualize it\n",
    "  * Create and design data distributions in CUQIpy for additive and multiplicative noise case and visualize it\n",
    "  * Compute the MAP estimate in CUQIpy\n",
    "  * Write the minimization problem that corresponds to finding the MAP estimate\n",
    "  * Sample from the posterior distribution in CUQIpy and visualize the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <font color=#CD853F>The forward model </font> <a class=\"anchor\" id=\"r-the-forward-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following inverse problem: given observed data $b$, determine $x_1$, and $x_2$:\n",
    "\n",
    "$$b = x_1 + x_2 + e \\;\\;\\mathrm{with}\\;\\; e \\sim \\mathrm{Gaussain}(0, 0.1)$$\n",
    "\n",
    "We can write it as:\n",
    "\n",
    "$$b = \\mathbf{A}\\mathbf{x} + e = \\large(1,1\\large)\\binom{x_1}{x_2} + e$$\n",
    "\n",
    "\n",
    "|variable     |    description          |dimension      |\n",
    "|:------------|:------------------------|:--------------|\n",
    "|$\\mathbf{x}$ |parameter to be inferred |2-dimensional​  |\n",
    "|$\\mathbf{A}$ |forward model            |1-by-2 matrix  |\n",
    "|$b$          |data                     | 1-dimensional |\n",
    "|$e$          |noise                    |1-dimensional  ​|\n",
    "\n",
    "This problem is:\n",
    "* Considered Linear inverse problem since the forward model is linear.\n",
    "* Ill-posed since solution not unique (Hadamard 2), i.e., for some given value of $b$, e.g., $b=3$, all points $(x_1, x_2)$ that satisfy $x_1 + x_1 = 3$ are solutions to the (noise-free) problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from cuqi.distribution import Gaussian\n",
    "from cuqi.problem import BayesianProblem\n",
    "from cuqi.model import LinearModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the forward model $\\mathbf{A}$, we first define the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_matrix = np.array([[1.0, 1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the dimension of the forward model matrix $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wrap `A_matrix` in a `CUQIpy` forward model object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = LinearModel(A_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test applying the forward model to some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_x = np.array([1.0, 2.0])\n",
    "print(A@some_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#8B4513>Exercise </font>\n",
    "1. Try applying `A` to a different input array\n",
    "2. Create a new linear forward model `B` that represents the identity matrix of dimension 3 and apply it to some parameters\n",
    "3. Print both of the models with `print(A)` and `print(B)`, what do you observe?\n",
    "4. Run `help(LinearModel)` to see the documentation of the class and the input arguments\n",
    "5. Is this true for you: **\"I learned how to create a linear forward model object in CUQIpy and apply it to some parameters.\"**? If not, what questions do you have?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <font color=#8B4513>Elaboration on Geometries </font> \n",
    "\n",
    "In CUQIpy, we have the concept of geometries to represent spaces of parameters and data, let us refer to both as variables. \n",
    "- A `Geometry` object will define the dimension of the space of the variable.\n",
    "- It will define the interpretation of the variable values (e.g. values of function on a 1D or 2D grid, discrete values, coefficients in some expansion, image pixels, etc). \n",
    "- It is equipped with methods of plotting the variables.\n",
    "\n",
    "We notice that printing the forward model object `A`, for example, gives us\n",
    "\n",
    "```\n",
    "CUQI LinearModel: _DefaultGeometry1D(2,) -> _DefaultGeometry1D(1,).\n",
    "    Forward parameters: ['x'].\n",
    "```\n",
    "- The first geometry `_DefaultGeometry1D(2,)` is the `domain_geometry` which represents the input space of the forward model, i.e., the space of the parameters $x_1$ and $x_2$.\n",
    "- The second geometry `_DefaultGeometry1D(1,)` is the `range_geometry` which represents the output space of the forward model, i.e., the space of the data $b$.\n",
    "- The forward parameters `['x']` are the parameters that the forward model operates on, in this case, the parameters $x_1$ and $x_2$.\n",
    "- You can access the domain and range geometries of the forward model object `A` by `A.domain_geometry` and `A.range_geometry` respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.domain_geometry)\n",
    "print(A.range_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `_DefaultGeometry1D` is a simple geometry that is used as a default geometry in CUQIpy if the user does not specify a geometry.\n",
    "- We will revisit this concept at a later stage depending on forward models needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#CD853F>The prior </font> <a class=\"anchor\" id=\"r-the-prior\"></a>\n",
    "\n",
    "### Bayesian approach: Use prior to express belief about solution\n",
    "A common choice for simplicity is the zero mean Gaussian prior where the components are independent and identically distributed (i.i.d.):\n",
    "\n",
    "$$ \\mathbf{x} \\sim \\mathrm{Gaussian}(\\mathbf{0}, \\delta^2 \\mathbf{I})$$\n",
    "\n",
    "The probability density function (PDF) of such a Gaussian prior is expressed as\n",
    "\n",
    "$$ \\pi (\\mathbf{x}) = \\frac{1}{\\sqrt{(2 \\pi)^n \\delta^{2n}}} \\mathrm{exp}\\left(-\\frac{||\\mathbf{x}||^2}{2\\delta^2}\\right) $$\n",
    "\n",
    "where:\n",
    "- $n$ is the dimension of the parameter space (which is 2 in this specific case),\n",
    "- $\\delta$ is the standard deviation of the prior distribution,\n",
    "- $\\mathbf{I}$ is the identity matrix.\n",
    "\n",
    "Let us define the prior distribution for the parameters $x_1$ and $x_2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Gaussian(np.zeros(2), 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot2d(val, x1_min, x1_max, x2_min, x2_max, N2=201):\n",
    "    # plot\n",
    "    pixelwidth_x = (x1_max-x1_min)/(N2-1)\n",
    "    pixelwidth_y = (x2_max-x2_min)/(N2-1)\n",
    "\n",
    "    hp_x = 0.5*pixelwidth_x\n",
    "    hp_y = 0.5*pixelwidth_y\n",
    "\n",
    "    extent = (x1_min-hp_x, x1_max+hp_x, x2_min-hp_y, x2_max+hp_y)\n",
    "\n",
    "    plt.imshow(val, origin='lower', extent=extent)\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "def plot_pdf_2D(distb, x1_min, x1_max, x2_min, x2_max, N2=201):\n",
    "    N2 = 201\n",
    "    ls1 = np.linspace(x1_min, x1_max, N2)\n",
    "    ls2 = np.linspace(x2_min, x2_max, N2)\n",
    "    grid1, grid2 = np.meshgrid(ls1, ls2)\n",
    "    distb_pdf = np.zeros((N2,N2))\n",
    "    for ii in range(N2):\n",
    "        for jj in range(N2):\n",
    "            distb_pdf[ii,jj] = np.exp(distb.logd([grid1[ii,jj], grid2[ii,jj]])) \n",
    "    plot2d(distb_pdf, x1_min, x1_max, x2_min, x2_max, N2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the prior PDF for the parameters $x_1$ and $x_2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf_2D(x, x1_min=-5, x1_max=5, x2_min=-5, x2_max=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample from the prior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples = x.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the samples from the prior distribution, one way to do this is to plot samples pair plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples.plot_pair()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#8B4513>Exercise </font>\n",
    "1. Can you generate one plot where you visualize the prior PDF and the pair plot together? (tip: after plotting the PDE, you can pass the `pyplot` current axis to `plot_pair` method by passing the keyword argument `ax=plt.gca()`)\n",
    "2. Does the samples seem to represent the prior distribution correctly?\n",
    "3. `x_1` and `x_2` of the prior distribution are independent and identically distributed random variables. In this exercise:\n",
    "    a. Define a new Gaussian distribution `x_exercise` where `x_1` and `x_2` are correlated with covariance of 0.7. Set `x_1` variance to 1 and `x_2` variance to 4 for. The covariance matrix is given by:\n",
    "    \n",
    "    $$\\begin{bmatrix} 1 & 0.7 \\\\ 0.7 & 4 \\end{bmatrix}$$\n",
    "4. Visualize the PDF of the new distribution `x_exercise` and the pair plot of the samples from the distribution in one plot. What do you observe?\n",
    "5. Is this true for you: **\"I learned how to create a distribution object in CUQIpy that represents the prior, sample it, and visualize it\"**? If not, what questions do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#CD853F> The noise distribution </font> <a class=\"anchor\" id=\"r-the-noise-distribution\"></a>\n",
    "\n",
    "- As mentioned earlier, we assume $e \\sim \\mathrm{Gaussain}(0, 0.1)$ \n",
    "- We can define the noise distribution as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Gaussian(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the noise distribution object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We draw some samples from the noise distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = e.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize them. One way to do that is to use the trace plot in `CUQIpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.plot_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left is a kernel density estimation (KDE) of the samples, and on the right is the trace plot of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also plot the PDF of the noise distribution, using the python function `plot_pdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_pdf_1D(distb, min, max):\n",
    "    grid = np.linspace(min, max, 1000)\n",
    "    y = [distb.pdf(grid_point) for grid_point in grid]\n",
    "    plt.plot(grid, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf_1D(e, -1.5, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#8B4513>Exercise </font>\n",
    "1. Create another noise distribution `e_exercise` with mean 0 and variance 0.5 and plot its PDF\n",
    "2. Plot the PDF of the noise distribution `e_exercise` and the noise distribution `e` on the same plot\n",
    "3. What do you observe?\n",
    "4. Is this true for you: **\"I learned how to create a distribution object in CUQIpy that represents the noise level and visualize it\"**? If not, what questions do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#CD853F> The data distribution </font> <a class=\"anchor\" id=\"r-the-data-distribution\"></a>\n",
    "\n",
    "The noise in the measurement data follows $e \\sim \\mathrm{Gaussain}(0, 0.1)$ and due to the relation $b = \\mathbf{A}\\mathbf{x} + e $, we can write\n",
    "\n",
    "$$ b | \\mathbf{x} \\sim \\mathrm{Gaussian}(\\mathbf{A}\\mathbf{x}, \\sigma^2\\mathbf{I})$$\n",
    "\n",
    "and in this case we specify $\\sigma^2 = 0.1$.\n",
    "\n",
    "$$ \\pi (b | \\mathbf{x}) = \\frac{1}{\\sqrt{(2 \\pi)^m \\sigma^{2m}}} \\mathrm{exp}\\left(-\\frac{||\\mathbf{A}\\mathbf{x}- b||^2}{2\\sigma^2}\\right) $$\n",
    "\n",
    "- The data distribution is the conditional distribution of $b$ given $\\mathbf{x}$.\n",
    "- This PDF can only be evaluated for a given $\\mathbf{x}$.\n",
    "\n",
    "We create the data distribution object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Gaussian(A@x, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the data distribution object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can not sample from this distribution directly. If we try, we will get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we catch the error and print it\n",
    "try:\n",
    "    b.sample(10)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before sampling or evaluating the PDF of `b`, we need to specify the value of the parameters `x`, let us choose the following value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particular_x = np.array([1.5, 1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we condition the data distribution `b` on the given parameter `particular_x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_given_particular_x = b(x=particular_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the distribution object `b_given_particular_x` that represents the data distribution given a particular value of the parameters `x`. We can now plot the PDF of this distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf_1D(b_given_particular_x, 1.5, 4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `b_given_particular_x` to simulate noisy data assuming that the true `x` parameters is `particular_x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_obs = b_given_particular_x.sample()\n",
    "print(b_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#8B4513>Exercise </font>\n",
    "1. Print the distribution object `b_given_particular_x`, how does the output differ from printing `b`.\n",
    "2. What is the ratio of the noise in the data (the noise in `b_obs`) to the true data.\n",
    "3. Explain how the data distribution is different from the noise distribution.\n",
    "4. Assume we have a multiplicative noise case in which the level of the noise depends on the model output, i.e., $b =  (\\mathbf{A}\\mathbf{x}) e$ where $e \\sim \\mathrm{Gaussain}(1, 0.1)$. \n",
    "    - What is the corresponding data distribution? \n",
    "    - Define the data distribution in CUQIpy and call it `b_mult`. Plot its PDF (condition on `particular_x`). Tip: you can use lambda function to define the `Gaussian` covariance `lambda x : 0.1*(A@x)**2`.\n",
    "    - Plot the PDF of the data distribution `b_mult` given `x=particular_x`.\n",
    "    - In general, for the given `x_particular`, how does the noise to the exact data ratio change in the case of `b_mult` compared to `b`? \n",
    "    - Plot the PDF of the data distribution `b_mult` given a different value of `x=np.array([0.4, 0.3])`. What can we say about the noise ratio to the exact data in this case? and why?\n",
    "5. Is this true for you: **\"I learned how to create and design data distributions in CUQIpy and visualize it for a given parameter\"**? If not, what questions do you have?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#CD853F> The likelihood function </font> <a class=\"anchor\" id=\"r-the-likelihood-function\"></a>\n",
    "\n",
    "\n",
    "Likelihood function: by fixing observed data $b^\\mathrm{obs}$ in the data distribution and considering the function of $\\mathbf{x}$:\n",
    "\n",
    "$$L (\\mathbf{x} | b^\\mathrm{obs}) \\mathrel{\\vcenter{:}}= \\pi (b^\\mathrm{obs} | \\mathbf{x})$$\n",
    "\n",
    "\n",
    "Example, given observed data  $b^\\mathrm{obs} $\n",
    "\n",
    "$$L (x_1, x_2 | b=b^\\mathrm{obs}) = \\frac{1}{\\sqrt{2 \\pi \\cdot 0.1}} \\mathrm{exp}\\left(-\\frac{(x_1+x_2- b^\\mathrm{obs})^2}{2\\cdot 0.1}\\right) $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CUQIpy, we can define the likelihood function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = b(b=b_obs)\n",
    "print(likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the likelihood function is a density function and is not a distribution. If we try to compute `pdf` for example, we will get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    likelihood.pdf(x=particular_x)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while for example, we can evaluate the pdf for the distribution `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.pdf(particular_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the likelihood function, we can evaluate its log-density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood.logd(x=particular_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the likelihood function for the observed data `b_obs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_lim = np.array([-5, 5])\n",
    "x2_lim = np.array([-5, 5])\n",
    "plot_pdf_2D(\n",
    "    likelihood,\n",
    "    x1_min=x1_lim[0], x1_max=x1_lim[1],\n",
    "    x2_min=x2_lim[0], x2_max=x2_lim[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <font color=#CD853F> Maximum likelihood (ML) point estimate </font> <a class=\"anchor\" id=\"r-maximum-likelihood-ml-point-estimate\"></a>\n",
    "\n",
    "\n",
    "- Equivalently, minimizer of negative log of likelihood\n",
    "- In the case of Gaussian noise is the least-squares solution\n",
    "\n",
    "$$\\mathbf{x}^* = \\underset{\\mathbf{x}}{\\operatorname{argmin\\;}} \\frac{1}{2 \\sigma^2} ||\\mathbf{A}\\mathbf{x}- b^\\mathrm{obs}||_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot likelihood function again but with line $x_2 = b^{obs}-x_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the likelihood\n",
    "plot_pdf_2D(\n",
    "    likelihood,\n",
    "    x1_min=x1_lim[0], x1_max=x1_lim[1],\n",
    "    x2_min=x2_lim[0], x2_max=x2_lim[1])\n",
    "\n",
    "# Plot the line x2 = b_obs - x1\n",
    "plt.plot(x1_lim, b_obs-x1_lim, '--r')\n",
    "plt.ylim(x2_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "- All the points on the line $x_2 = b^{obs}-x_1$ have the same likelihood value. \n",
    "- No unique ML point\n",
    "- This is expected, since problem we are solving is: $b^{obs} = x_1 + x_2$\n",
    "- Combining the likelihood with the prior will give us a unique maximum a posteriori (MAP) point estimate as we will see next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#CD853F> The posterior distribution </font> <a class=\"anchor\" id=\"r-posterior\"></a>\n",
    "### Bayes’ rule\n",
    "- The posterior is proportional to product of **likelihood** and **prior**\n",
    "$$\\pi(\\mathbf{x} | b) \\propto \\pi( b|\\mathbf{x})\\pi(\\mathbf{x})$$\n",
    "\n",
    "- Note that $\\pi( b|\\mathbf{x})$ here denotes the likelihood and not the data distribution, despite often written that way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CUQIpy, we can use the class `BayesianProblem` to bundle the prior, the data distribution, and the data, then use it to explore the posterior distribution (e.g. point estimate and sampling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP = BayesianProblem(b, x)\n",
    "print(BP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pass the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP.set_data(b=b_obs)\n",
    "print(BP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference in the target of the `BayesianProblem` object before and after passing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#CD853F> Maximum a posteriori (MAP) estimate </font> <a class=\"anchor\" id=\"r-maximum-a-posteriori-map-estimate\"></a>\n",
    " \n",
    "- Maximizer of the posterior\n",
    "\n",
    "$$\\mathbf{x}^* = \\underset{\\mathbf{x}}{\\operatorname{argmax\\;}} \\pi(\\mathbf{x} | b)$$\n",
    "- In the case with Gaussian noise and Gaussian prior, this is the classic Tikhonov solution\n",
    "\n",
    "$$\\mathbf{x}^* = \\underset{\\mathbf{x}}{\\operatorname{argmin\\;}} \\frac{1}{2 \\sigma^2} ||\\mathbf{A}\\mathbf{x}- b^\\mathrm{obs}||_2^2 + \\frac{1}{2\\delta^2}||\\mathbf{x} ||^2_2$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=#8B4513>Exercise </font>\n",
    "1. Use the `BayesianProblem` object to compute the MAP estimate. Objects of the class `BayesianProblem` have a method `MAP` that computes the MAP estimate.\n",
    "2. Print the solution (the MAP estimate) and compare it to the true solution `particular_x`, what do you observe? If they are different, why?\n",
    "3. Is this true for you: **\"I learned how to compute the MAP estimate in CUQIpy\"**? If not, what questions do you have?\n",
    "4. Is this true for you: **\"In paper and pencil, I can write the minimization problem that corresponds to finding the MAP estimate\"**? If not, what questions do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#CD853F> Sampling from the posterior </font> <a class=\"anchor\" id=\"r-sampling-from-the-posterior\"></a> \n",
    "\n",
    "The MAP point is a very useful point estimate, but it does not provide information about the uncertainty in the estimate. Thus, we need to sample from the posterior distribution to quantify the uncertainty.\n",
    "\n",
    "Before sampling from the posterior distribution, let us plot the posterior distribution. \n",
    "\n",
    "**Note** that in this example the posterior distribution is a multivariate distribution of two parameters only and it is easy to evaluate the PDF of the posterior distribution over a grid of points in the parameter space. However, typically, the posterior distribution is high-dimensional and evaluating the PDF over an n-dimensional grid is not feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf_2D(BP.posterior, x1_lim[0], x1_lim[1], x2_lim[0], x2_lim[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#8B4513>Exercise </font>\n",
    "1. Use the `BayesianProblem` object to sample from the posterior distribution. Objects of the class `BayesianProblem` have a method `sample_posterior` that samples from the posterior distribution. You can use `help(BP.sample_posterior)` to see the documentation of the method.\n",
    "2. The method `sample_posterior` returns a `Samples` object, which is the same type of object that is returned by the `sample` method of the `Distribution` class. Visualize the posterior samples using the `plot_trace` method of the `Samples` object.\n",
    "3. Similar to what you did for the prior, plot the pair plot of the posterior samples over the prior PDF (in the same plot). Are the samples consistent with the posterior distribution PDF?\n",
    "4. Is this true for you: **\"I learned how to sample from the posterior distribution in CUQIpy and visualize the samples\"**? If not, what questions do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
