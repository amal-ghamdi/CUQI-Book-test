{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 01: Hamiltonian Monte Carlo with CUQIpy-PyTorch\n",
    "\n",
    "In this exercise, we will use the [CUQIpy-PyTorch](https://github.com/CUQI-DTU/CUQIpy-PyTorch) plugin to sample arbitrary probability distributions using the No U-Turn (NUTS) variant of Hamiltonian Monte Carlo (HMC). Make sure you have installed the plugin before starting this exercise.\n",
    "\n",
    "## Learning objectives of this notebook:\n",
    "- ...\n",
    "\n",
    "## Table of contents: \n",
    "* [1. xxx](#xxx)\n",
    "* [2. yyy ★](#yyy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the necessary packages. Notice we use the PyTorch package `torch` instead of NumPy for arrays and import both `cuqi` and `cuqi_torch` from CUQIpy and CUQIpy-PyTorch, respectively.\n",
    "\n",
    "The main idea of the CUQIpy-PyTorch package is to leverage the automatic differentiation capabilities of PyTorch to compute the gradients of the log-probability function. To achieve this everything we use must work with PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as xp\n",
    "import cuqi\n",
    "import cuqipy_pytorch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the `cuqi` distributions are written using NumPy and SciPy, we instead have to use the distributions defined in `cuqi_torch`. These are thin wrappers around PyTorch distributions, but acts as a drop-in replacement for the `cuqi` distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuqipy_pytorch.distribution import Gaussian, HalfGaussian, LogGaussian, Uniform, Gamma, StackedJointDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the highly optimized NUTS sampler from the `pyro` package, which is conviniently wrapped in the `cuqi_torch` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuqipy_pytorch.sampler import NUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a simple function to sample the posterior given densities and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A convenience function to sample a Bayesian model\n",
    "def sample(*densities, Ns=500, Nb=500, **data):\n",
    "    \"\"\" Sample given by a list of densities. The observations are given as keyword arguments. \"\"\"\n",
    "    P = StackedJointDistribution(*densities)\n",
    "    return NUTS(P(**data)).sample(Ns, Nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 400/400 [00:57,  7.02it/s, step size=3.52e-02, acc. prob=0.170]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DATA_URL = \"https://raw.githubusercontent.com/fonnesbeck/probabilistic_python/master/data/\"\n",
    "spin_rate_data = pd.read_csv(DATA_URL + \"savant_data.csv\", parse_dates=[\"game_date\"]).dropna(subset=[\"spin_rate\", \"game_date\"])\n",
    "\n",
    "day_ind, date = pd.factorize(spin_rate_data.game_date, sort=True)\n",
    "spin_rate = spin_rate_data.spin_rate.values\n",
    "day_ind = xp.tensor(day_ind)\n",
    "\n",
    "#spin_rate_data.head()\n",
    "#spin_rate_data.plot.scatter(x=\"game_date\", y=\"spin_rate\", figsize=(14,5), alpha=0.2)\n",
    "\n",
    "mu = Gaussian(xp.ones(2)*2500, 100)\n",
    "tau = Uniform(0, 181)\n",
    "sigma = HalfGaussian(100)\n",
    "r = lambda tau, mu: xp.where(day_ind < tau, mu[0], mu[1])\n",
    "sr = LogGaussian(r, lambda sigma: sigma)\n",
    "\n",
    "samples = sample(mu, tau, sigma, sr, Ns=200, Nb=200, sr=spin_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A simple example\n",
    "\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xp.linspace(-10, 10, 100)\n",
    "y = x**3-27*x - 8\n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eight schools\n",
    "The eight schools model is a classic example made famous by the Bayesian Data Analysis book by Gelman et. al. \n",
    "\n",
    "It is often used to illustrate the notation and code-style of probabilistic programming languages. \n",
    "\n",
    "The actual model is explained in the BDA book or in the Edward 1.0 PPL notebook ([link](https://github.com/blei-lab/edward/blob/master/notebooks/eight_schools.ipynb)).\n",
    "\n",
    "The Bayesian model can be written as\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mu &\\sim \\mathcal{N}(0, 10^2)\\\\\n",
    "    \\tau &\\sim \\log\\mathcal{N}(5, 1)\\\\\n",
    "    \\boldsymbol \\theta' &\\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_m)\\\\\n",
    "    \\boldsymbol \\theta &= \\mu + \\tau \\boldsymbol \\theta'\\\\\n",
    "    \\mathbf{y} &\\sim \\mathcal{N}(\\boldsymbol \\theta, \\boldsymbol \\sigma^2 \\mathbf{I}_m)\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathbf{y}\\in\\mathbb{R}^m$ and $\\boldsymbol \\sigma\\in\\mathbb{R}^m$ is observed data.\n",
    "\n",
    "In CUQIpy we can define the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs = xp.tensor([28, 8, -3,  7, -1, 1,  18, 12], dtype=xp.float32)\n",
    "σ_obs = xp.tensor([15, 10, 16, 11, 9, 11, 10, 18], dtype=xp.float32)\n",
    "\n",
    "μ     = Gaussian(0, 10**2)\n",
    "τ     = LogGaussian(5, 1)\n",
    "θp    = Gaussian(xp.zeros(8), 1)\n",
    "θ     = lambda μ, τ, θp: μ+τ*θp\n",
    "y     = Gaussian(θ, cov=σ_obs**2)\n",
    "\n",
    "samples = sample(μ, τ, θp, y, y=y_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior samples\n",
    "samples[\"θp\"].plot_violin(); \n",
    "print(samples[\"μ\"].mean()) # Average effect\n",
    "print(samples[\"τ\"].mean()) # Average variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot treatment effect distribution\n",
    "θs = []\n",
    "for μs, τs, θps in zip(samples[\"μ\"], samples[\"τ\"], samples[\"θp\"]):\n",
    "    θs.append(θ(μs, τs, θps))\n",
    "    \n",
    "θs = cuqi.samples.Samples(xp.tensor(θs).T)\n",
    "θs.geometry._name = \"θ\"\n",
    "θs.plot_violin();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SciPy forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try yourself\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39df9cdae8ebf7efb1525026a7ebb7fcd202c6f8c14fe7ef64f5e199bee61274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
